{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Company Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_com_list = pd.read_csv('wikiPageNew2019MS.csv',encoding = 'big5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wmflabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver.get(\"https://tools.wmflabs.org/pageviews/?project=en.wikipedia.org&platform=all-access&agent=user&start=2015-07-01&end=2019-12-31&pages=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sleep(3)\n",
    "driver.find_element_by_xpath(\"//span[@class='clear-pages pull-right']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0,len(ms_com_list)):\n",
    "    input_element = driver.find_element_by_class_name(\"select2-search__field\")#找到要輸入的地方\n",
    "    input_element.send_keys(search_list['wiki.page'][i])#輸入公司名\n",
    "    sleep(5)\n",
    "    input_element.send_keys(Keys.ENTER)#按enter\n",
    "    count+=1\n",
    "    if count==10 or i == (len(ms_com_list)-1):\n",
    "        sleep(5)\n",
    "        driver.find_element_by_xpath(\"//div[@class='chart-buttons']/div[@class='btn-group dropdown download-btn-group']/button[@class='btn btn-default btn-sm dropdown-toggle']\").click()#按下載\n",
    "        driver.find_element_by_class_name(\"download-csv\").click()#按csv\n",
    "        count = 0\n",
    "        driver.find_element_by_xpath(\"//span[@class='clear-pages pull-right']\").click()#清除搜尋內容\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1,len(ms_com_list)):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys(ms_com_list['g'][i])\n",
    "    input_element.submit()\n",
    "    driver.save_screenshot(ms_com_list['g'][i]+'.jpg')\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Screenshots to fing corresponding WikiPage of a Company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1,len(ms_com_list)):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys(ms_com_list['g'][i]+'('+ms_com_list['TICKER'][i]+')')\n",
    "    input_element.submit()\n",
    "    driver.save_screenshot(ms_com_list['g'][i]+ms_com_list['TICKER'][i]+')'+'.jpg')\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "\n",
    "ms_com_list = pd.read_csv('missingData_ms.csv')\n",
    "for i in np.arange(1,len(ms_com_list)):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys(ms_com_list['g'][i])\n",
    "    input_element.submit()\n",
    "    driver.save_screenshot(ms_com_list['g'][i]+'_ms.jpg')\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "for i in np.arange(1,len(ms_com_list)):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys(ms_com_list['g'][i]+'('+ms_com_list['TICKER'][i]+')')\n",
    "    input_element.submit()\n",
    "    driver.save_screenshot(ms_com_list['g'][i]+ms_com_list['TICKER'][i]+')'+'_ms.jpg')\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "\n",
    "for i in np.arange(1,1565):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys(ms_com_list['COMNAM'][i]+' company'+' wiki')\n",
    "    input_element.submit()\n",
    "    temp=driver.find_element_by_xpath('//div[@class=\"bkWMgd\"][1]//span[@class=\"S3Uucc\"]')\n",
    "    webtitle = temp.text\n",
    "    if ' - Wikipedia' in webtitle:\n",
    "        ms_com_list['WikiPage'][i]=webtitle\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "\n",
    "for i in np.arange(0,len(ms_com_list)):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys(ms_com_list['COMNAM'][i]+' company'+' wiki')\n",
    "    input_element.submit()\n",
    "    temp=driver.find_element_by_xpath('//div[@class=\"bkWMgd\"][1]//span[@class=\"S3Uucc\"]')\n",
    "    webtitle = temp.text\n",
    "    if ' - Wikipedia' in webtitle:\n",
    "        ms_com_list['WikiPage'][i]=webtitle\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "ms_com_list.to_csv('Wikipage_com_selenium_.csv')\n",
    "\n",
    "ms_com_list = pd.read_excel('missing_com.xlsx')\n",
    "ms_com_list['WikiPage'] = 'missing' \n",
    "\n",
    "\n",
    " for i in np.arange(1263,1565):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys('wikipedia '+ ms_com_list['COMNAM'][i])\n",
    "    input_element.submit()\n",
    "    temp=driver.find_element_by_xpath('//div[@class=\"bkWMgd\"][1]//span[@class=\"S3Uucc\"]')\n",
    "    webtitle = temp.text\n",
    "    if ' - Wikipedia' in webtitle:\n",
    "        ms_com_list['WikiPage'][i]=webtitle\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "for i in np.arange(1566,len(ms_com_list)):\n",
    "    driver.get(\"http://www.google.com\")\n",
    "    input_element = driver.find_element_by_name(\"q\")\n",
    "    input_element.send_keys('wikipedia '+ ms_com_list['COMNAM'][i])\n",
    "    input_element.submit()\n",
    "    temp=driver.find_element_by_xpath('//div[@class=\"bkWMgd\"][1]//span[@class=\"S3Uucc\"]')\n",
    "    webtitle = temp.text\n",
    "    if ' - Wikipedia' in webtitle:\n",
    "        ms_com_list['WikiPage'][i]=webtitle\n",
    "    print(i/len(ms_com_list))\n",
    "    sleep(5)\n",
    "    \n",
    "ms_com_list.to_csv('Wikipedia_selenium_Nostrip.csv',encoding = 'utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
